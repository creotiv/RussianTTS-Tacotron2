{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('hifigan/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import soundfile as sf\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence, symbol_to_id\n",
    "from text.cleaners import transliteration_ua_cleaners, english_cleaners, transliteration_cleaners,transliteration_cleaners_with_stress\n",
    "from text.rudict import RuDict\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "\n",
    "from hifigan.meldataset import MAX_WAV_VALUE\n",
    "from hifigan.models import Generator\n",
    "from hifigan.env import AttrDict\n",
    "\n",
    "from audio_processing import get_mel\n",
    "\n",
    "loaded = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='lower', \n",
    "                       interpolation='none')\n",
    "    plt.savefig('out.png')\n",
    "    ipd.display(ipd.Image('out.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050\n",
    "# hparams.end_symbols_ids = [symbol_to_id[s] for s in '?!.']\n",
    "# hparams.use_gst = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"outdir/checkpoint_2500\"\n",
    "model = Tacotron2(hparams).cuda()\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict']) #,map_location=torch.device('cpu')\n",
    "_ = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16 torch.Size([1, 80, 872])\n"
     ]
    }
   ],
   "source": [
    "ref_mel = get_mel('test/me1.wav', hparams).type(torch.HalfTensor).cuda()\n",
    "print(ref_mel.dtype, ref_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.5586, -6.9414, -6.6484,  ..., -5.7969, -4.7070, -3.5684],\n",
      "         [-6.6914, -6.9883, -6.5039,  ..., -5.3203, -4.1797, -3.1133],\n",
      "         [-6.5273, -7.0859, -7.3281,  ..., -2.0859, -1.9082, -2.1719],\n",
      "         ...,\n",
      "         [-4.7383, -4.3242, -3.8496,  ..., -7.1875, -7.8164, -7.9922],\n",
      "         [-4.6680, -4.4102, -3.7910,  ..., -7.1836, -7.6211, -8.4766],\n",
      "         [-4.7852, -4.5273, -4.2148,  ..., -7.7656, -8.1797, -8.6328]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(ref_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sn+och', +ulitsa, fon+ar', apt+eka. bessm+yslennyi, i t+usklyi sv+et. zhiv+i eshch+e kh+ot' ch+etvert' v+eka - vs+io b+udet t+ak. iskh+oda n+et.E\n",
      "[[12 27 40 28 16 21  3  6 11 40 34 25 22 33 32 14  6 11 19 28 27 40 14 31\n",
      "   3  6 11 14 29 33 40 18 24 14  7 11 15 18 32 32 26 40 38 32 25 18 27 27\n",
      "  38 22  6 11 22 11 33 40 34 32 24 25 38 22 11 32 35 40 18 33  7 11 39 21\n",
      "  22 35 40 22 11 18 32 21 16 21 40 18 11 24 21 40 28 33  3 11 16 21 40 18\n",
      "  33 35 18 31 33  3 11 35 40 18 24 14 11  1 11 35 32 40 22 28 11 15 40 34\n",
      "  17 18 33 11 33 40 14 24  7 11 22 32 24 21 40 28 17 14 11 27 40 18 33  7\n",
      "  13]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Тетрагидропиранилциклопентилтетрагидропиридопиридиновые вещества\".lower()\n",
    "text = \"Мин+истр здравоохран+ения улет+ел. И обещ+ал верн+уться. С вакц+инами. Нав+ерно, +есть как+ой-то м+ир, где мин+истрам л+ично н+адо лет+ать за вакц+инами с четырьм+я перес+адками во вр+емя эпид+емии. М+ожет по+этому в Зимб+абве уже вакцин+ируют, потом+у чт+о их мин+истр л+ично с+ел на слон+а и по+ехал на нем в больш+ой г+ород преклон+ить кол+ено и получ+ить вакц+ину? Так+ой м+ир нам пыт+аются прод+ать?\".lower()\n",
    "# text = \"Вс+е смеш+алось в д+оме Обл+онских. Жен+а узн+ала, что муж был в св+язи с б+ывшею в их д+оме франц+уженкою-гуверн+анткой, и объяв+ила м+ужу, что не м+ожет ж+ить с ним в одн+ом д+оме. Полож+ение это продолж+алось уже третий д+ень и муч+ительно ч+увствовалось и сам+ими супр+угами, и вс+еми чл+енами семь+и, и домоч+адцами.\"\n",
    "# text = \"Тв+орог или твор+ог, к+озлы или козл+ы, з+амок или зам+ок.\".lower()\n",
    "# text=\"мн+е хот+елось б+ы? сказ+ать к+ак я призн+ателен вс+ем прис+утсвующим сд+есь.\"\n",
    "# text = \"tak+oi m+ir n+am pyt+aiutsia prod+at'?\"\n",
    "# text = \"Как пройти в дом?\"\n",
    "# text = \"В+ыйду,,,,,,, н+очью,,, в п+оле,,, с кон+ем\"\n",
    "text = \"Н+очь, +улица, фон+арь, апт+ека. Бессм+ысленный, и т+усклый св+ет. Жив+и ещ+е х+оть ч+етверть в+ека - Вс+ё б+удет т+ак. Исх+ода н+ет.\"\n",
    "# text = \"Ночь, улица, фонарь, аптека. Бессмысленный, и тусклый свет. Жив+и еще хоть четверть века - Все будет так. Исхода нет.\"\n",
    "# text = \"Игра - тип осмысленной непродуктивной деятельности, где мотив лежит не в её результате, а в самом процессе. Также термин игра используют для обозначения набора предметов или программ, предназначенных для подобной деятельности.\"\n",
    "# text = \"Прижм+ись к+о мн+е кр+епче и бл+иже. Не ж+ил я,, блужд+ал ср+едь чуж+их. О с+он м+ой,, Я н+овое в+ижу, В бред+у поцел+уев тво+их!\"\n",
    "\n",
    "# text = \"Тогд+а почем+у ж+е я ощущ+аю себ+я н+а гр+ани физ+ической катастр+офы?\"\n",
    "# text =\"Ты согласен?\"\n",
    "# text = \"Здр+аствуйте, мен+я зов+ут Андр+ей Никиш+аев, я с+иньер архит+ектор в комп+ании манив+ео. П+о мо+им д+анным у в+ас не закр+ытый кред+ит на с+умму в+осемдесят тр+и т+ысячи тр+иста шестдес+ят тр+и гр+ивны. Н+ужно погас+ить!\"\n",
    "# text = \"С к+аждым дн+ем весн+ы стан+овится вс+е тепл+ее, а +это р+адость для к+аждого вод+ителя.\"\n",
    "# text = \"Молод+ой парн+ишка Т+анг С+ан одн+ажды оступ+ился и сл+едуя сво+им жел+аниям и пр+ихотям вор+ует секр+етные уч+ения в своей школе боевых искусств.\"\n",
    "\n",
    "print(transliteration_cleaners_with_stress(text))\n",
    "sequence = np.array(text_to_sequence(text, ['transliteration_cleaners_with_stress']))[None, :]\n",
    "print(sequence)\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = ('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# bit8_model = torch.quantization.quantize_dynamic(\n",
    "#         model, {torch.nn.LSTM, torch.nn.Linear, torch.nn.LSTMCell, torch.nn.GRUCell}, dtype=torch.qint8\n",
    "# )\n",
    "\n",
    "# print(model_size(bit8_model))\n",
    "# for name, module in bit8_model.named_modules():\n",
    "#     if isinstance(module, torch.nn.Conv1d):\n",
    "#         prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "#     elif isinstance(module, torch.nn.Linear):\n",
    "#         prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "   \n",
    "# print(model_size(bit8_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# np.random.seed(16)\n",
    "\n",
    "z_scale = np.ones(32, dtype=np.float32)\n",
    "z_scale[7] = 1.0\n",
    "\n",
    "_, mel_outputs, mel_outputs_postnet, _, alignments, emb2 = model.inference(sequence,seed=None,scale=1.0, token_idx=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = False\n",
    "def load_checkpoint(filepath, device):\n",
    "    assert os.path.isfile(filepath)\n",
    "    print(\"Loading '{}'\".format(filepath))\n",
    "    checkpoint_dict = torch.load(filepath, map_location=device)\n",
    "    print(\"Complete.\")\n",
    "    return checkpoint_dict\n",
    "\n",
    "if not loaded:\n",
    "    device = torch.device('cuda')\n",
    "    with open('hifigan/config.json') as fp:\n",
    "        json_config = json.load(fp)\n",
    "        h = AttrDict(json_config)\n",
    "    generator = Generator(h).to(device)\n",
    "\n",
    "    state_dict_g = load_checkpoint(\"hifigan/g_02500000\", device)\n",
    "    generator.load_state_dict(state_dict_g['generator'])\n",
    "    generator.eval()\n",
    "    generator.remove_weight_norm()\n",
    "    \n",
    "#     generator = torch.quantization.quantize_dynamic(\n",
    "#         generator, {torch.nn.LSTM, torch.nn.Linear, torch.nn.LSTMCell, torch.nn.GRUCell}, dtype=torch.qint8\n",
    "#     )\n",
    "    loaded=True\n",
    "\n",
    "def inference(mel, generator):\n",
    "    \n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_g_hat = generator(mel)\n",
    "        audio = y_g_hat.squeeze()\n",
    "        audio = audio * MAX_WAV_VALUE\n",
    "        audio = audio.detach().cpu().numpy()#.astype('int16')\n",
    "\n",
    "        return audio\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.perf_counter()\n",
    "mel = mel_outputs_postnet.type(torch.float32)\n",
    "print(time.perf_counter()-s)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "audio = inference(mel, generator)\n",
    "ipd.Audio(audio, rate=hparams.sampling_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    z_scale = np.ones(32, dtype=np.float32)\n",
    "    z_scale[10] = 1.5\n",
    "\n",
    "    _, mel_outputs, mel_outputs_postnet, _, alignments, emb2 = model.inference(sequence,seed=1234,z_scale=z_scale, reference_mel=ref_mel)\n",
    "    mel = mel_outputs_postnet.type(torch.float32)\n",
    "    audio = inference(mel, generator)\n",
    "    sf.write('res/z_%s.wav' % i, audio*0.0002, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = F.normalize(vect, dim=1).detach().cpu().numpy()\n",
    "res =  cs(norm, norm)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(emb1.detach().cpu().numpy()[0][0] - emb2.detach().cpu().numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb1.detach().cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
